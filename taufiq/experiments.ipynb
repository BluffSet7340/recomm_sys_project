{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c86c5a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc65f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceab8e4",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824c41d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/kk6cvpy92zvfzcj5gr5l6c6h0000gn/T/ipykernel_12916/1413335316.py:1: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../dataset/weighted_score_above_08.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>appid</th>\n",
       "      <th>game</th>\n",
       "      <th>author_steamid</th>\n",
       "      <th>author_num_games_owned</th>\n",
       "      <th>author_num_reviews</th>\n",
       "      <th>author_playtime_forever</th>\n",
       "      <th>author_playtime_last_two_weeks</th>\n",
       "      <th>author_playtime_at_review</th>\n",
       "      <th>author_last_played</th>\n",
       "      <th>...</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>hidden_in_steam_china</th>\n",
       "      <th>steam_china_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147449116</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>76561199183984450</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "      <td>2548</td>\n",
       "      <td>0</td>\n",
       "      <td>2480</td>\n",
       "      <td>1696305457</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.889438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147374264</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>76561198099573060</td>\n",
       "      <td>226</td>\n",
       "      <td>13</td>\n",
       "      <td>2369</td>\n",
       "      <td>0</td>\n",
       "      <td>2361</td>\n",
       "      <td>1696096555</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>8</td>\n",
       "      <td>0.914834</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147357703</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>76561199080026894</td>\n",
       "      <td>118</td>\n",
       "      <td>23</td>\n",
       "      <td>13501</td>\n",
       "      <td>212</td>\n",
       "      <td>12957</td>\n",
       "      <td>1697630734</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>599</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968375</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147345102</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>76561198068970227</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>10668</td>\n",
       "      <td>640</td>\n",
       "      <td>9906</td>\n",
       "      <td>1698261011</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>0.826206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147284743</td>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>76561199137893460</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>543</td>\n",
       "      <td>10</td>\n",
       "      <td>526</td>\n",
       "      <td>1697810991</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>24</td>\n",
       "      <td>0.853612</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendationid  appid            game     author_steamid  \\\n",
       "0         147449116     10  Counter-Strike  76561199183984450   \n",
       "1         147374264     10  Counter-Strike  76561198099573060   \n",
       "2         147357703     10  Counter-Strike  76561199080026894   \n",
       "3         147345102     10  Counter-Strike  76561198068970227   \n",
       "4         147284743     10  Counter-Strike  76561199137893460   \n",
       "\n",
       "   author_num_games_owned  author_num_reviews  author_playtime_forever  \\\n",
       "0                      51                  12                     2548   \n",
       "1                     226                  13                     2369   \n",
       "2                     118                  23                    13501   \n",
       "3                      28                   1                    10668   \n",
       "4                      19                   5                      543   \n",
       "\n",
       "   author_playtime_last_two_weeks  author_playtime_at_review  \\\n",
       "0                               0                       2480   \n",
       "1                               0                       2361   \n",
       "2                             212                      12957   \n",
       "3                             640                       9906   \n",
       "4                              10                        526   \n",
       "\n",
       "   author_last_played  ... voted_up votes_up  votes_funny  \\\n",
       "0          1696305457  ...        1       99            2   \n",
       "1          1696096555  ...        1      122            8   \n",
       "2          1697630734  ...        1      599           20   \n",
       "3          1698261011  ...        1       59           12   \n",
       "4          1697810991  ...        1      128           24   \n",
       "\n",
       "   weighted_vote_score  comment_count  steam_purchase  received_for_free  \\\n",
       "0             0.889438              0               1                  0   \n",
       "1             0.914834              0               1                  0   \n",
       "2             0.968375              3               1                  0   \n",
       "3             0.826206              0               0                  0   \n",
       "4             0.853612              0               1                  0   \n",
       "\n",
       "   written_during_early_access  hidden_in_steam_china  steam_china_location  \n",
       "0                            0                      1                   NaN  \n",
       "1                            0                      1                   NaN  \n",
       "2                            0                      1                   NaN  \n",
       "3                            0                      1                   NaN  \n",
       "4                            0                      1                   NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/weighted_score_above_08.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be50e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined_df.json', 'r') as f:\n",
    "    sample_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1897df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract valid appids from the sample file\n",
    "valid_appids = {entry['appid'] for entry in sample_data}\n",
    "\n",
    "# Filter df based on appids in the sample\n",
    "df = df[df['appid'].isin(valid_appids)]\n",
    "\n",
    "# Continue processing\n",
    "df_games = df[['appid', 'game']]\n",
    "df_games = df_games.drop_duplicates(subset='appid')\n",
    "\n",
    "appid2game = df_games.set_index('appid')['game'].to_dict()\n",
    "game2appid = df_games.set_index('game')['appid'].to_dict()\n",
    "\n",
    "del df_games\n",
    "\n",
    "df = df[['appid', 'author_steamid', 'voted_up']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcf44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "appid2genres = {entry['appid']: entry['genre'] for entry in sample_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d39735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appid', 'author_steamid', 'voted_up'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appid2game # dictionary from appid to game name\n",
    "appid2genres # dictionary from appid to list of string genres\n",
    "df.columns\n",
    "# Index(['appid', 'author_steamid', 'voted_up'], dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44a095",
   "metadata": {},
   "source": [
    "# Validation Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0ce455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = df[df['voted_up'] == 1]\n",
    "all_appids = set(df['appid'].unique())\n",
    "\n",
    "df_pos = df[df['voted_up'] == 1].copy()\n",
    "\n",
    "# 1) Build *global* mappings on the entire positive set\n",
    "all_users = df_pos['author_steamid'].unique()\n",
    "all_items = df_pos['appid'].unique()\n",
    "\n",
    "user_ids     = {u: idx for idx, u in enumerate(all_users)}\n",
    "item_ids     = {i: idx for idx, i in enumerate(all_items)}\n",
    "user_ids_inv = {idx: u for u, idx in user_ids.items()}\n",
    "item_ids_inv = {idx: i for i, idx in item_ids.items()}\n",
    "\n",
    "# Create train/test split by user\n",
    "def train_test_split_per_user(df, test_size=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    train_rows, test_rows = [], []\n",
    "\n",
    "    for user, user_df in tqdm(df.groupby('author_steamid'), desc=\"Splitting train/test by user\"):\n",
    "        if len(user_df) < 2:\n",
    "            train_rows.append(user_df)\n",
    "        else:\n",
    "            user_train, user_test = train_test_split(user_df, test_size=test_size)\n",
    "            train_rows.append(user_train)\n",
    "            test_rows.append(user_test)\n",
    "\n",
    "    train_df = pd.concat(train_rows)\n",
    "    test_df = pd.concat(test_rows)\n",
    "    return train_df, test_df\n",
    "\n",
    "def sample_negatives(test_df, train_df, num_negatives=50):\n",
    "    user_pos_train = train_df.groupby('author_steamid')['appid'].apply(set).to_dict()\n",
    "    user_pos_test = test_df.groupby('author_steamid')['appid'].apply(set).to_dict()\n",
    "    \n",
    "    test_data = []\n",
    "\n",
    "    for user in tqdm(user_pos_test, desc=\"Sampling negatives\"):\n",
    "        pos_items = user_pos_test[user]\n",
    "        neg_items = list(all_appids - user_pos_train.get(user, set()) - pos_items)\n",
    "        sampled_negatives = random.sample(neg_items, min(num_negatives, len(neg_items)))\n",
    "        \n",
    "        for pos_item in pos_items:\n",
    "            test_data.append((user, pos_item, 1))\n",
    "        for neg_item in sampled_negatives:\n",
    "            test_data.append((user, neg_item, 0))\n",
    "    \n",
    "    return pd.DataFrame(test_data, columns=['author_steamid', 'appid', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c86bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df['voted_up'] == 1].copy()\n",
    "\n",
    "# 1) Build *global* mappings on the entire positive set\n",
    "all_users = df_pos['author_steamid'].unique()\n",
    "all_items = df_pos['appid'].unique()\n",
    "\n",
    "user_ids     = {u: idx for idx, u in enumerate(all_users)}\n",
    "item_ids     = {i: idx for idx, i in enumerate(all_items)}\n",
    "user_ids_inv = {idx: u for u, idx in user_ids.items()}\n",
    "item_ids_inv = {idx: i for i, idx in item_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57d83082",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_true_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbb5ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(relevance, k):\n",
    "    relevance = np.array(relevance)[:k]\n",
    "    if relevance.size == 0:\n",
    "        return 0.0\n",
    "    return np.sum(relevance / np.log2(np.arange(2, relevance.size + 2)))\n",
    "\n",
    "def ndcg_at_k(preds, true_items, k):\n",
    "    relevance = [1 if item in true_items else 0 for item in preds[:k]]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    dcg = dcg_at_k(relevance, k)\n",
    "    idcg = dcg_at_k(ideal_relevance, k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def average_precision_at_k(preds, true_items, k):\n",
    "    hits, score = 0, 0.0\n",
    "    for i, item in enumerate(preds[:k]):\n",
    "        if item in true_items:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1)\n",
    "    if not true_items:\n",
    "        return 0.0\n",
    "    return score / min(len(true_items), k)\n",
    "\n",
    "def evaluate(test_data, recommender_fn, k=10, use_cache=False):\n",
    "    global user_to_true_cache\n",
    "    user_to_preds = defaultdict(list)\n",
    "\n",
    "    if use_cache and 'user_to_true_cache' in globals():\n",
    "        user_to_true = user_to_true_cache\n",
    "    else:\n",
    "        user_to_true = defaultdict(set)\n",
    "        for _, row in tqdm(test_data.iterrows(), total=len(test_data), desc=\"Processing test data\"):\n",
    "            user, appid, label = row['author_steamid'], row['appid'], row['label']\n",
    "            if label == 1:\n",
    "                user_to_true[user].add(appid)\n",
    "        if use_cache:\n",
    "            user_to_true_cache = user_to_true\n",
    "\n",
    "    n = 0\n",
    "    for user in tqdm(user_to_true, desc=\"Generating predictions\"):\n",
    "        n += 1\n",
    "        preds = recommender_fn(user)[:k]\n",
    "        user_to_preds[user] = preds\n",
    "\n",
    "    # print(f\"Success rate: {successes / n:.2%}\")\n",
    "    # input()\n",
    "    precisions, recalls, ndcgs, mapks = [], [], [], []\n",
    "\n",
    "    for user in tqdm(user_to_true, desc=\"Calculating metrics\"):\n",
    "        true_items = user_to_true[user]\n",
    "        pred_items = user_to_preds[user]\n",
    "\n",
    "        num_hit = len(set(pred_items) & true_items)\n",
    "        precision = num_hit / k\n",
    "        recall = num_hit / len(true_items) if len(true_items) > 0 else 0\n",
    "        ndcg = ndcg_at_k(pred_items, true_items, k)\n",
    "        mapk = average_precision_at_k(pred_items, true_items, k)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        ndcgs.append(ndcg)\n",
    "        mapks.append(mapk)\n",
    "\n",
    "    results = {\n",
    "        'Precision@K': np.mean(precisions),\n",
    "        'Recall@K': np.mean(recalls),\n",
    "        'NDCG@K': np.mean(ndcgs),\n",
    "        'MAP@K': np.mean(mapks)\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1c474",
   "metadata": {},
   "source": [
    "# Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ebe77",
   "metadata": {},
   "source": [
    "## Popularity-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split_per_user(df_pos)\n",
    "test_data = sample_negatives(test_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many users liked each item in the training data\n",
    "item_popularity = train_df['appid'].value_counts()\n",
    "\n",
    "# Recommend the top-N popular items for all users\n",
    "top_k = 10\n",
    "top_items = item_popularity.head(top_k).index.tolist()\n",
    "\n",
    "# For each user, generate recommendations\n",
    "def recommend_popular(user_id):\n",
    "    return top_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82797d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2047143/2047143 [00:25<00:00, 79034.35it/s]\n",
      "Generating predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39976/39976 [00:00<00:00, 3510636.22it/s]\n",
      "Calculating metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39976/39976 [00:00<00:00, 114204.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@K: 0.0043\n",
      "Recall@K: 0.0384\n",
      "NDCG@K: 0.0199\n",
      "MAP@K: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(test_data, recommend_popular, k=10)\n",
    "\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36219d",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Implicit ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3a5846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mgt_flask/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6eeeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_split(df, user_col='author_steamid', seed=42):\n",
    "    np.random.seed(seed)\n",
    "    test_indices = []\n",
    "\n",
    "    # Collect one test index per user with >1 interaction\n",
    "    for user, group in tqdm(df.groupby(user_col), desc=\"Leave-one-out (fast)\"):\n",
    "        if len(group) > 1:\n",
    "            test_idx = np.random.choice(group.index, size=1)[0]\n",
    "            test_indices.append(test_idx)\n",
    "\n",
    "    # Convert to sets for fast lookup\n",
    "    test_indices_set = set(test_indices)\n",
    "    \n",
    "    # Use Boolean mask for efficient slicing\n",
    "    mask = df.index.isin(test_indices_set)\n",
    "    test_df  = df.loc[mask].reset_index(drop=True)\n",
    "    train_df = df.loc[~mask].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219fb12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leave-one-out (fast): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320412/320412 [00:01<00:00, 166237.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loo_df, test_loo_df = leave_one_out_split(df_pos, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a265ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build user/item mappings from the ENTIRE dataset (not just training)\n",
    "all_user_ids = {uid: idx for idx, uid in enumerate(df_pos['author_steamid'].unique())}\n",
    "all_item_ids = {iid: idx for idx, iid in enumerate(df_pos['appid'].unique())}\n",
    "all_item_ids_inv = {v: k for k, v in all_item_ids.items()}\n",
    "\n",
    "# Step 2: Add index columns to the entire dataset\n",
    "df_pos['user_idx'] = df_pos['author_steamid'].map(all_user_ids)\n",
    "df_pos['item_idx'] = df_pos['appid'].map(all_item_ids)\n",
    "\n",
    "# Step 3: Now split AFTER indexing\n",
    "train_df, test_df = train_test_split_per_user(df_pos)\n",
    "\n",
    "# Step 4: Build matrix only from train data, but use global user/item shapes\n",
    "item_user_matrix = coo_matrix(\n",
    "    (np.ones(len(train_df)), (train_df['item_idx'], train_df['user_idx'])),\n",
    "    shape=(len(all_item_ids), len(all_user_ids))\n",
    ").tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c035953",
   "metadata": {},
   "source": [
    "## Content-Aware: LightFM With Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd459cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting train/test by user: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320412/320412 [00:11<00:00, 28447.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split_per_user(df_pos)  # same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3340d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit users, items, and item features (genres)\n",
    "dataset.fit(train_df['author_steamid'], appid2genres.keys())\n",
    "all_genres = set(g for genres in appid2genres.values() for g in genres)\n",
    "dataset.fit_partial(items=train_df['appid'], item_features=all_genres)\n",
    "\n",
    "# Build interactions\n",
    "interactions, _ = dataset.build_interactions(\n",
    "    ((row['author_steamid'], row['appid']) for _, row in train_df.iterrows())\n",
    ")\n",
    "\n",
    "# Build item features\n",
    "item_features = dataset.build_item_features(\n",
    "    ((appid, appid2genres.get(appid, [])) for appid in appid2genres)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14b14fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x382864160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model_lfm = LightFM(loss='warp')\n",
    "model_lfm.fit(interactions, item_features=item_features, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859109ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_lightfm(user_id, k=10):\n",
    "    if user_id not in user_ids:\n",
    "        return top_items  # fallback\n",
    "\n",
    "    user_idx = user_ids[user_id]\n",
    "    scores = model_lfm.predict(user_ids[user_id], np.arange(len(item_ids)), item_features=item_features)\n",
    "    top_indices = np.argsort(-scores)[:k]\n",
    "    return [item_ids_inv[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b606c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2047143/2047143 [00:25<00:00, 80710.47it/s]\n",
      "Generating predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39976/39976 [01:15<00:00, 531.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39976/39976 [00:00<00:00, 110374.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@K: 0.0001\n",
      "Recall@K: 0.0004\n",
      "NDCG@K: 0.0003\n",
      "MAP@K: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(test_data, recommend_lightfm, k=10)\n",
    "\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgt_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
